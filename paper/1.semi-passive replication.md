# semi-passive replication

(本文属于原创内容，首发于https://github.com/dragon-distributed/book , 未经作者许可，不得转载。)  
## 背景
semi-passive replication这篇paper是一篇比较老的paper，是2002年8月在IEEE中published的。paper可以在https://ieeexplore.ieee.org/document/740473/citations#citations 中找到。  

这篇paper提出了一种semi-passive(半被动复制)的技术，paper中称之为passive replication的一个变种，它可以使得在经典的passive replication复制模型中，去掉membership的依赖。   

本文计划先介绍主流的两种复制模型：active and passive replication，然后再介绍semi-passive replication。  

## Active replication

Active replication是Leslie Lamport大神在state machine replication中提出的。  

![active replication](https://longdandan-1256672193.cos.ap-guangzhou.myqcloud.com/article/paper/1.active-replication.jpg)

简单理解，active replication其实是实现一种"fan-out"语义，也就是说，client会将request发往所有的servers，每个server单独执行，并单独响应client。为了保证每个server都按一致的顺序接收消息，需要有技术保障（atomic broadcast protocol）。  

这种模式的最大好处，就是latency比较低，因为一跳完成了。  

缺点就是：  
1) high resource usage (paper中指出)
2) 所有servers的处理是确定性的。意思是，按相同的初始状态，有相同的client requests，需要有相同的结果。  

其实对于第2点，我对实现的理解是：要保证同一时间只有一个writer，一般实现使用write proxy或者zk+client抢主的方式进行。想想业界比较有名的，大概有twitter的Distributed Log(proxy模式)，Hbase2.0的AsyncFSWriter。

## Passive replication

也叫primary-backup：

![Passive replication](https://longdandan-1256672193.cos.ap-guangzhou.myqcloud.com/article/paper/1.passive-replication.jpg)

这类的系统就很常见了，基于binlog replication的MySQL，基于Raft的ETCD、Consul、TiDB，基于ZAB的ZK，基于Proxy的Phxsql等等。  

这类系统的主要缺点就是，需要membership的管理，而且在leader crash之后，有一定时间的downtime，而这段时间对于client的请求，一般是timeout。   

对于这种服务中断，一般需要trade-off leader timeout时间，如果较激进，则可能会出现较多误判，如果较保守，则downtime较长。

在这一章节中，论文指出，可以考虑系统中的两个不同的超时值，一个激进，一个保守，积极的超时值仅用于怀疑崩溃的replica（不将其从组中排除），而保守的超时值可用于从组中踢出replica。  

## Semi-passive replication

我打算把paper思想表达出来，太细节的，待用时或者需要工程实现时，再复查。

semi-passive有几个关键点：  

1) 不需要membership management：不需要类似raft的leader detection/election，而使用rotate的方式："it is based on the rotating coordinator paradigm that has been used for solv- ing the consensus problem"。  

这样子的话，就可以使用两个timeout时间，一个激进的timeout用于backups怀疑primary crash，一个保守的timeout用于将crash节点移除。

2) client是直接发request到所有节点，但只有一个节点进行replication(也就是primary会进行复制，回到passive replication模式)。在primary crash时，client也能收到响应。

我们来具体看看例子。

### Good run

![good run](https://longdandan-1256672193.cos.ap-guangzhou.myqcloud.com/article/paper/1.goodrun.jpg)

简单地说，就是 
1) client send request到所有的replica。  
2) replica中有一个是primary，他会处理请求，并进行同步。  
3) 待其它replica ack后(可以是majority或者其它具体工程需要的场景），到commit阶段（decide）。  
4) 每个replica收到decide message，则马上apply，并reply到client。client只要等到第一个reply即可(论文："as the client waits only for the first reply, the latency of the client corresponds indeed to 4 communication steps.")  

### worst case

在异常的情况下，最坏的case看下图：

![worst case](https://longdandan-1256672193.cos.ap-guangzhou.myqcloud.com/article/paper/1.worstcases.jpg)

可以看出，在primary crash时:  

1) 所有的replica会发nack message到primary(p1)。  
2) 如果primary没有回应的话，则发estimate message到p2(the new primary，为什么是p2，可能跟上文说的rotate策略有关)，当p2收到majority的estimate时，就可以继续后续流程。
3) 由于p2有收到client的request, 所以这次的request会继续处理，而不会丢掉。  

### improving the failure resilience

论文在最后，给出一些在实现中的针对fail场景的improvement。如有5有replica，分别是p1-p5，则对他们做一个排列，比如[p1,p2,p3,p4,p5]，第一个是first coordinator(primary)，如果crashed，则把它移后，变成[p2,p3,p4,p5,p1]，p2成为coordinator，这样可以快速地把影响控制在有限的范围。

##  结论

semi-passive replication个人还没发现有具体的实现，但是是一个非常好的思路，在工程实践中可以借鉴。