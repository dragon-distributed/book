# In Search of a Key Value Store with High Performance and High Availability

(本文属于原创内容，首发于https://github.com/dragon-distributed/book , 未经作者(龙永超)许可，不得转载。)  

## 背景

这篇paper，本人是作者之一，本文是把paper的核心思想进行讲解，便于大家阅读此paper。  

本篇paper，提出了一个高性能、高可用的分布式Key Value Store：LogStore，相对于业界常见的分布式KV存储，LogStore有几个核心优化点，也是此paper的contribution：  

1) Log as Database  
2) Single Thread Per Partition Executing Mode  
3) Low Overhead Data Buffer Pool Management  
4) Freshness  

## Log as Database

Log as database是LogStore的核心思想。  

业界的单机存储引擎，如基于LSM-Tree的RocksDB，已经有过许许多多的优化，但本质还是WAL+Data这种Dual-Copy的架构：WAL提高写入性能以及保证数据不丢失，Data则是以目标数据结构保存，用于数据的检索。虽然LSM-Tree使用Memory+分层文件的方式对性能进行了优化，但Dual-Copy的架构最终会导致一份Data，要保存两份：WAL+Data，而在性能上，则要两次写入：WAL+Memory Data。  

分布式KV存储，在传统的RSM(Replication State Machine)模型下，也是Dual-Copy的架构：Log + State Machine。Log是用于复制，State Machine一般是单机存储引擎，只是不再需要WAL。在这种架构下，也是会导致一份Data要保存两份。  

Log as database的思想则是把WAL+Data合拼起来，一份数据，既是LOG与也是Data，这有助于最大化地增加Throughput以及增少latency。  

LogStore中，数据存储在LOG中，在内存中使用ART(Adaptive Radix Tree)进行索引。Log as database除了上述增加Throughput以及增少latency外，在RSM-Style的分布式系统中，同样会减少Primary-Secondary之间commitment的GAP。  

ART的细节可以在paper：The Adaptive Radix Tree: ARTful Indexing for Main-Memory Databases中详细了解。总体来说，ART的优势在于单点的检索性能、插入删除性能以及存储空间，劣势在于对scan支持不友好。  

## Single Thread Per Partition Executing Mode

这里主要有两个技术点，一个是CPU Affinity，另一个是Latch-free。  

CPU Affinity是指将线程与CPU的核绑定，以避免CPU调度过程中context switch时的消耗。在LogStore中，绑定的是handle Partition的Thread。  

Latch-free是指无锁化，即ART以及相关的数据结构，如Cache的无锁化。每个Partition一个Thread，一个Thread绑定在一个Core中，一个Partition对应自己独立的数据，包括ART、Cache等。  

跨Partition的search如何解决呢？LogStore中的Key采用Hash Key + Sorted Key组成，Hash Key对应Partition的分组计算。可以在应用写入时，指定相同的HashKey让数据都集中在相同的分区。  

## Low Overhead Data Buffer Pool Management

缓存可以用于加速读取。一般的缓存，会有置换算法，如FIFO，Clock，LRU，算法中会有一些统计信息，如LRU一般使用双向链表，这会增加一些消耗。在LogStore中，我们创造了一种second-chance-like的名叫TwoStage的算法。如下图所示：  

![图一](https://longdandan-1256672193.cos.ap-guangzhou.myqcloud.com/article/distributed/4.buff.jpg)

我们把buff分层两部分，一部分是热区，另一部分是冷区，冷区大概占10%的空间，使用FIFO淘汰策略。当热区的数据量达到阀值时，系统会随机将热区的数据放入到冷区，若后续的操作，会用到冷区的数据，则把它放回到热区。在一段时间后（如热区再次达到阀值），将仍然在冷区地数据清掉。  

我们测试过TwoStage与LRU、FIFO的性能，在不同的缓存命中率下，性能均稍稍好于LRU、FIFO。具体见Paper的实验数据部分。  

## Freshness

Freshness是个很大的话题。在Passive Replication的系统中，Primary与Secondary的commit/apply总会有gap的，Log as Database的思想，会减少这个gap(因为apply时间明显减少)，但不能消除这个gap。从primary读或者从secondary读，会涉及到一致性问题，因为从secondary读可能会stale-read。  

LogStore中的Freshness可以理解成更灵活的一致性选择。

最初始的功能，用户在写入后，response会带上LSN(Log Sequence Number)，那用户在secondary发出读请求时，带上LSN，则secondary会保证读到LSN之后的数据。  

有了这个LSN，就可以做很多延伸了，比如通过meta server获取某个key的最新LSN，在secondary中进行强一致性读，又或者在replica前面搭建proxy，proxy可以知道primary的LSN，可以将读请求带上此LSN在secondary进行强一致性读等等。  

## 总体

本文简单介绍了本人的paper: In Search of a Key Value Store with High Performance and High Availability中的核心思想，带着这些理解去阅读论文会简单一些，更详细的细节请阅读论文。  